= Jenkins DSL Pipeline

The repository contains job definitions using https://wiki.jenkins-ci.org/display/JENKINS/Job+DSL+Plugin[Jenkins Job Dsl plugin]. Those jobs will form an empty pipeline and a sample, opinionated one that you can use in your company.

The projects that take part in the whole setup are:

- https://github.com/dsyer/github-analytics[Github-Analytics] - the app that has a REST endpoint and uses messaging. Our app under test
- https://github.com/marcingrzejszczak/github-eureka[Eureka] - simple Eureka Server
- https://github.com/marcingrzejszczak/github-analytics-stub-runner-boot[Github Analytics Stub Runner Boot] - Stub Runner Boot server to be used for tests with Github Analytics. Uses Eureka and Messaging.
- https://github.com/marcingrzejszczak/atom-feed[Github Webhook] - project that uses Github-Analytics

== Step by step

- Fork repos
- Start PCF Dev (if you don't want to use an existing one)
- Start Docker Compose with Jenkins + Artifactory
- Setup Jenkins env vars (if you want to use the demo defaults and you're using Docker Machine
just check out the section on how to update the URL to Artifactory)
- Setup Jenkins miscs (JDK installation, Groovy macro processing etc.)
- Setup Jenkins credentials
- Add `settings.xml` for Jenkins' master (you can skip this if you want to use our defaults)
- Modify the seed job

=== Fork repos

There are 4 apps that are composing the pipeline

  - https://github.com/marcingrzejszczak/atom-feed[Github Webhook]
  - https://github.com/dsyer/github-analytics/[Github Analytics]
  - https://github.com/marcingrzejszczak/github-eureka[Github Eureka]
  - https://github.com/marcingrzejszczak/github-analytics-stub-runner-boot[Github Stub Runner Boot]

You need to fork only these. That's because only then will your user be able to tag and push the tag to repo.

  - https://github.com/marcingrzejszczak/atom-feed[Github Webhook]
  - https://github.com/dsyer/github-analytics/[Github Analytics]

For the other two

  - https://github.com/marcingrzejszczak/github-eureka[Github Eureka]
  - https://github.com/marcingrzejszczak/github-analytics-stub-runner-boot[Github Stub Runner Boot]

You have to build locally and upload their artifacts to Artifactory.

If you're running without Docker Machine (e.g. for Github Eureka):

[source,bash]
----
git clone https://github.com/marcingrzejszczak/github-eureka
cd github-eureka
./mvnw clean deploy
----

If you're running with Docker Machine (e.g. it's running on 192.168.99.100):

[source,bash]
----
git clone https://github.com/marcingrzejszczak/github-eureka
cd github-eureka
./mvnw clean deploy -Ddistribution.management.release.url=http://192.168.99.100:8081/artifactory/libs-release-local
----

=== Start PCF Dev

TIP: You can skip this step if you have CF installed already

You have to download and start PCF Dev. https://pivotal.io/platform/pcf-tutorials/getting-started-with-pivotal-cloud-foundry-dev/install-pcf-dev[A link how to do it is available here.]

The default credentials when using PCF Dev are:

[source,bash]
----
username: user
password: pass
email: user
org: pcfdev-org
space: pcfdev-space
api: api.local.pcfdev.io
----

You can start the PCF dev with more memory

[source,bash]
----
cf dev start -m 6144
----

You'll have to create 3 separate spaces (email admin, pass admin)

[source,bash]
----
cf login -a https://api.local.pcfdev.io --skip-ssl-validation -u admin -p admin -o pcfdev-org

cf create-space pcfdev-test
cf set-space-role user pcfdev-org pcfdev-test SpaceDeveloper
cf create-space pcfdev-stage
cf set-space-role user pcfdev-org pcfdev-stage SpaceDeveloper
cf create-space pcfdev-prod
cf set-space-role user pcfdev-org pcfdev-prod SpaceDeveloper
----

IMPORTANT: Most likely you will run out of memory so when reaching the stage
environment it's good to kill all apps on test. You can do it like this:

E.g. for `github-webhook` app

[source,bash]
----
cf target -o pcfdev-org -s pcfdev-test
cf stop github-webhook
cf stop github-eureka
cf stop stubrunner
----

=== Start Docker Compose

Jenkins + Artifactory can be ran locally. To do that just execute

`docker-compose up`

Then Jenkins will be running on port `8080` and Artifactory `8081`.

=== Setup Jenkins env vars

TIP: If you want to only play around with the demo that we've prepared
you can skip this section and use our defaults

IMPORTANT: If you're using a docker-machine then for sure you have to update
 the `REPO_WITH_JARS` to point to your Docker Machine address e.g. `192.168.99.100`
 instead of `localhost`

You need to be able to pass the environment variables to your jobs. Those
env vars are:

[frame="topbot",options="header,footer"]
|======================
|Property Name  | Property Description | Default value
|CF_API_URL | The URL to the CF Api | api.local.pcfdev.io
|CF_TEST_ORG    | Name of the org for the test env | pcfdev-org
|CF_TEST_SPACE  | Name of the space for the test env | pcfdev-space
|CF_STAGE_ORG   | Name of the org for the stage env | pcfdev-org
|CF_STAGE_SPACE | Name of the space for the stage env | pcfdev-space
|CF_PROD_ORG   | Name of the org for the prod env | pcfdev-org
|CF_PROD_SPACE | Name of the space for the prod env | pcfdev-space
|REPO_WITH_JARS | URL to repo with the deployed jars | http://localhost:8081/artifactory/libs-release-local
|M2_SETTINGS_REPO_ID | The id of server from Maven settings.xml | artifactory-local
|JDK_VERSION | The name of the JDK installation | jdk8
|======================

There's a number of ways to achieve it!

==== Global envs

You can add env vars (go to configure Jenkins -> Global Properties) for the following
 properties (the defaults are for PCF Dev):

Example screen:

image::docs/env_vars.png[]

==== Seed variables

Another approach is to run the seed job with parameters / env vars. Whatever
you set will be parsed by the seed job and passed to the generated Jenkins
jobs.

TIP: This is very useful when the repos you want to build differ. E.g. use
different JDK. Then some seeds can set the `JDK_VERSION` param to one version
of Java installation and the others to another one.

Example screen:

TODO: Add a screen

=== Additional setup

==== Enable Groovy Token Macro Processing

you need this to allow generation of Pipeline Version

image::docs/groovy_token.png[]

==== Provide your JDK version

- by default we assume that you have jdk with id `jdk8` configured
- if you want a different one just override `JDK_VERSION` env var and point to the proper one

=== Add Jenkins credentials for GitHub

The scripts will need to access the credentials for Cloud Foundry access.
Additionally there is one that is required in order to tag the repo.

In order for the scripts to find the credentials you have to pass the IDs
of the stored credentials. Below you can find the list of env vars that you
can set in order to find the proper credential. There are of course
some defaults too

[frame="topbot",options="header,footer"]
|======================
|Property Name  | Property Description | Default value
|GIT_CREDENTIAL_ID    | Credential used to tag a git repo | git
|CF_TEST_CREDENTIAL_ID  | Credential for CF Test env access | cf-test
|CF_STAGE_CREDENTIAL_ID   | Credential for CF Stage env access | cf-stage
|CF_PROD_CREDENTIAL_ID | Credential for CF Prod env access | cf-prod
|======================

Below you can find instructions on how to set a credential.

TODO: Add screens

=== Setup settings.xml for Maven deployment

TIP: If you want to use the default connection to the Docker version
of Artifactory you can skip this step

So that `./mvnw deploy` works with Artifactory from Docker we're
already copying the missing `settings.xml` file for you. It looks like this:

[source,bash]
----
<server>
  <id>artifactory-local</id>
  <username>admin</username>
  <password>password</password>
</server>
----

If you want to use your own version of Artifactory / Nexus you have to update
the file (it's in `seed/settings.xml`).

=== Modify the seed job

We already create the seed job for you but you'll have to modify it.

== FAQ

=== Pipeline version contains ${PIPELINE_VERSION}

You can check the Jenkins logs and you'll see

[source,bash]
----
WARNING: Skipped parameter `PIPELINE_VERSION` as it is undefined on `jenkins-pipeline-sample-build`.
	Set `-Dhudson.model.ParametersAction.keepUndefinedParameters`=true to allow undefined parameters
	to be injected as environment variables or
	`-Dhudson.model.ParametersAction.safeParameters=[comma-separated list]`
	to whitelist specific parameter names, even though it represents a security breach
----

To fix it you have to do exactly what the warning suggests...

=== Can I use the pipeline for some other repos?

Sure! you can pass `REPOS` variable with comma separated list of
`project_name$project_url` format. If you don't provide the PROJECT_NAME the
repo name will be extracted and used as the name of the project.

E.g. for `REPOS` equal to:

`https://github.com/dsyer/github-analytics,https://github.com/marcingrzejszczak/atom-feed`

will result in the creation of pipelines with root names `github-analytics` and `atom-feed`.

E.g. for `REPOS` equal to:

`foo$https://github.com/dsyer/github-analytics,bar$https://github.com/marcingrzejszczak/atom-feed`

will result in the creation of pipelines with root names `foo` for `github-analytics`
and `bar` for `atom-feed`.

=== I've ran out of resources!!

When deploying the app to stage or prod you can get an exception `Insufficient resources`. The way to
 solve it is to kill some apps from test / stage env. To achieve that just call

[source,bash]
----
cf target -o pcfdev-org -s pcfdev-test
cf stop github-webhook
cf stop github-eureka
cf stop stubrunner
----

== How to build it

`./gradlew clean build`

WARNING: The ran test only checks if your scripts compile.

== How to use it in Jenkins?

Check out the https://github.com/jenkinsci/job-dsl-plugin/wiki/Tutorial---Using-the-Jenkins-Job-DSL[tutorial].
Provide the link to this repository in your Jenkins installation.

The seed job for Spring Cloud should scan the `jobs/springcloud/*.groovy` files.

Remember to add `src/main/groovy` and `src/main/resources` for processing

WARNING: Remember that views can be overridden that's why the suggestion is to contain in one script all the logic needed to build a view
 for a single project (check out that `spring_cloud_views.groovy` is building all the `spring-cloud` views).
